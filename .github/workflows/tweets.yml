name: Scrape Tweets to Supabase

on:
  schedule:           # runs every 3 hours
    - cron:  '0 */3 * * *'
  workflow_dispatch:  # manual trigger

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      # ---- R setup -------------------------------------------------
      - uses: r-lib/actions/setup-r@v2
        with:
          r-version: '4.3'

      # system libs for RPostgres
      - name: Install system deps
        run: sudo apt-get update && sudo apt-get install -y libpq-dev python3-venv

      # ---- Python setup -------------------------------------------
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      # ---- Run the script -----------------------------------------
      - name: Run fetch_twitter_to_supabase.R
        env:
          # --- Supabase --------------------------------------------
          SUPABASE_HOST:   ${{ secrets.SUPABASE_HOST }}
          SUPABASE_PORT:   ${{ secrets.SUPABASE_PORT }}
          SUPABASE_DB:     ${{ secrets.SUPABASE_DB }}
          SUPABASE_USER:   ${{ secrets.SUPABASE_USER }}
          SUPABASE_PWD:    ${{ secrets.SUPABASE_PWD }}
          # --- Twitter ---------------------------------------------
          TW_COOKIES_JSON: ${{ secrets.TW_COOKIES_JSON }}
          TW_HANDLES:      ${{ vars.TW_HANDLES }}   # optional repo variable
          PY_VENV_PATH:    '.venv'
        run: |
          Rscript fetch_twitter_to_supabase.R
